{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.0+cpu\n"
     ]
    }
   ],
   "source": [
    "print(t.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.2755e-39, 1.0561e-38, 9.5510e-39],\n",
      "        [8.9082e-39, 9.4592e-39, 4.2246e-39],\n",
      "        [1.0286e-38, 1.0653e-38, 1.0194e-38],\n",
      "        [8.4490e-39, 1.0469e-38, 9.3674e-39],\n",
      "        [9.9184e-39, 8.7245e-39, 9.2755e-39]])\n",
      "tensor([[0.0787, 0.7452, 0.0479],\n",
      "        [0.5004, 0.4221, 0.3962],\n",
      "        [0.7225, 0.8788, 0.3133],\n",
      "        [0.6337, 0.0854, 0.8931],\n",
      "        [0.2155, 0.4889, 0.0119]])\n",
      "tensor([[ 0.8154, -1.8312,  0.0043],\n",
      "        [-0.9063,  1.6402, -0.7820],\n",
      "        [ 0.0418,  0.7248, -0.3524],\n",
      "        [-1.1139, -0.6979, -0.7691],\n",
      "        [-0.7585, -1.7303, -0.2356]])\n"
     ]
    }
   ],
   "source": [
    "####################################张量\n",
    "n1=t.empty(5,3)#未初始化\n",
    "print(n1)\n",
    "\n",
    "n2=t.rand(5,3)#随机初始化\n",
    "print(n2)\n",
    "\n",
    "n3=t.randn(5,3)#从正态分布中随机取数 \n",
    "print(n3)\n",
    "#t.ones, t.zeros分别是全1初始化和全0初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.2000, 5.0000, 3.0000]) torch.Size([3]) torch.FloatTensor\n",
      "tensor([[5., 5., 3.]]) torch.Size([1, 3]) torch.FloatTensor\n",
      " \n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "n4=t.Tensor([5.2,5.0,3])#直接从数据构造张量\n",
    "\n",
    "n5=t.Tensor([[5,5,3]])   #中括号‘[]’类似于张量的维度标志\n",
    "\n",
    "n6=t.tensor([[1,2,3],[4,5,6]])#要注意中括号[]\n",
    "print(n4,n4.size(),n4.type())\n",
    "print(n5,n5.size(),n5.type())\n",
    "print(\" \")\n",
    "print(n6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]]])\n",
      " \n",
      "z[0]= tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      " \n",
      "z[0,0]= tensor([0., 0., 0.])\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#张量元素的访问\n",
    "z=t.zeros(2,5,3)\n",
    "print(z)\n",
    "print(\" \")\n",
    "print(\"z[0]=\",z[0])#访问z的第一个元素\n",
    "print(\" \")\n",
    "print(\"z[0,0]=\",z[0,0])#访问z的第一个元素的第一行\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.6624, 1.7210, 1.2190],\n",
      "        [1.1160, 1.2184, 1.3170],\n",
      "        [1.8770, 1.2515, 1.5803],\n",
      "        [1.3650, 1.5778, 1.4657],\n",
      "        [1.3006, 1.4302, 1.7274]])\n",
      "tensor([[1.6624, 1.7210, 1.2190],\n",
      "        [1.1160, 1.2184, 1.3170],\n",
      "        [1.8770, 1.2515, 1.5803],\n",
      "        [1.3650, 1.5778, 1.4657],\n",
      "        [1.3006, 1.4302, 1.7274]])\n",
      "tensor([[1.6624, 1.7210, 1.2190],\n",
      "        [1.1160, 1.2184, 1.3170],\n",
      "        [1.8770, 1.2515, 1.5803],\n",
      "        [1.3650, 1.5778, 1.4657],\n",
      "        [1.3006, 1.4302, 1.7274]])\n",
      "tensor([[1.6624, 1.7210, 1.2190],\n",
      "        [1.1160, 1.2184, 1.3170],\n",
      "        [1.8770, 1.2515, 1.5803],\n",
      "        [1.3650, 1.5778, 1.4657],\n",
      "        [1.3006, 1.4302, 1.7274]])\n",
      "tensor([[1.6624, 1.7210, 1.2190],\n",
      "        [1.1160, 1.2184, 1.3170],\n",
      "        [1.8770, 1.2515, 1.5803],\n",
      "        [1.3650, 1.5778, 1.4657],\n",
      "        [1.3006, 1.4302, 1.7274]])\n",
      "  \n",
      "tensor([[1, 2]]) torch.Size([1, 2])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]]) torch.Size([3, 1])\n",
      "tensor([[2, 3],\n",
      "        [3, 4],\n",
      "        [4, 5]]) torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "####################################张量的运算\n",
    "\n",
    "##加法\n",
    "x=t.ones(5,3)\n",
    "y=t.rand(5,3)\n",
    "#两种常用形式\n",
    "print(x+y)\n",
    "print(t.add(x,y))\n",
    "#指定输出\n",
    "m=t.empty(5,3)\n",
    "print(m)\n",
    "t.add(x,y,out=m)\n",
    "print(m)\n",
    "##原地加法操作（in_place）\n",
    "y.add_(x)     #任何一个改变张量的操作(in-place)后面都固定一个_ , 这将改变原有的数据    x.copy_(y);x.t_()都将改变x的值\n",
    "print(y)\n",
    "\n",
    "print(\"  \")\n",
    "#广播机制 适当复制元素使其形状相同然后运算\n",
    "x = t.arange(1, 3).view(1, 2)\n",
    "print(x,x.size())\n",
    "y = t.arange(1, 4).view(3, 1)\n",
    "print(y,y.size())\n",
    "print(x + y,(x+y).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7128, 0.7128, 0.7128, 0.7128, 0.7128],\n",
      "        [1.8253, 1.8253, 1.8253, 1.8253, 1.8253],\n",
      "        [0.7076, 0.7076, 0.7076, 0.7076, 0.7076],\n",
      "        [0.8019, 0.8019, 0.8019, 0.8019, 0.8019],\n",
      "        [0.8553, 0.8553, 0.8553, 0.8553, 0.8553]])\n"
     ]
    }
   ],
   "source": [
    "#############################张量的维度操作\n",
    "#矩阵乘法需要调用mm操作（matrix multiply） Tensor.mm（）\n",
    "x=t.rand(5,3)\n",
    "y=t.ones(5,3)\n",
    "print(x.mm(y.t()))#tensor.t()是矩阵的转置  矩阵乘法需A列=B行，结果取A行B列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x= tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]]) x.size= torch.Size([4, 2])\n",
      "y= tensor([[[1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.]]]) y.size= torch.Size([2, 2, 2])\n",
      " \n",
      "z= tensor([[[1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.]]]) z.size= torch.Size([2, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "###############改变形状tensor.view()\n",
    "#view后的张量与原张量同源 改变一个则都会变化\n",
    "x=t.ones(4,2)\n",
    "y=x.view(2,2,2)\n",
    "print(\"x=\",x,\"x.size=\",x.size())\n",
    "print(\"y=\",y,\"y.size=\",y.size()) \n",
    "z=x.view(2,1,-1)       \n",
    "##################view()操作括号中参数为-1是一种简便操作 , 表示自动计算该维度的元素个数保证重构前后元素个数相同\n",
    "print(\" \")\n",
    "print(\"z=\",z,\"z.size=\",z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6]]]) torch.Size([1, 2, 3])\n",
      "tensor([[[1, 4],\n",
      "         [2, 5],\n",
      "         [3, 6]]]) torch.Size([1, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "###########tensor.permute()\n",
    "#view的操作更像是将张量元素按位置顺序平铺后按规则截取\n",
    "#permute的操作则是在预原张量维度的基础上进行变换\n",
    "x=t.tensor([[[1,2,3],[4,5,6]]])\n",
    "print(x,x.size())\n",
    "print(x.permute(0,2,1),x.permute(0,2,1).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]]) torch.Size([2, 3])\n",
      " \n",
      "tensor([[[0, 1, 2]],\n",
      "\n",
      "        [[3, 4, 5]]]) torch.Size([2, 1, 3])\n",
      " \n",
      "tensor([[[[[0, 1, 2],\n",
      "           [3, 4, 5]]]]]) torch.Size([1, 1, 1, 2, 3])\n",
      " \n",
      "tensor([[[[0, 1, 2],\n",
      "          [3, 4, 5]]]]) torch.Size([1, 1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "#########维度的压缩与扩张 tensor.squeese(), tensor.unsqueese()\n",
    "#指变换某个维度的1\n",
    "a=t.tensor([[0,1,2],[3,4,5]])\n",
    "print(a,a.size())\n",
    "print(\" \")\n",
    "b=a.unsqueeze(1)\n",
    "print(b,b.size())\n",
    "print(\" \")\n",
    "c=a.view(1,1,1,2,3)\n",
    "print(c,c.size())\n",
    "print(\" \")\n",
    "print(c.squeeze(0),c.squeeze(0).size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8385, 0.0563, 0.2292],\n",
      "        [0.8480, 0.8128, 0.3340]]) torch.Size([2, 3])\n",
      " \n",
      "tensor([[0.8385, 0.0563, 0.2292],\n",
      "        [0.8480, 0.8128, 0.3340],\n",
      "        [0.8385, 0.0563, 0.2292],\n",
      "        [0.8480, 0.8128, 0.3340],\n",
      "        [0.8385, 0.0563, 0.2292],\n",
      "        [0.8480, 0.8128, 0.3340]]) torch.Size([6, 3])\n",
      " \n",
      "tensor([[0.8385, 0.0563, 0.2292, 0.8385, 0.0563, 0.2292, 0.8385, 0.0563, 0.2292],\n",
      "        [0.8480, 0.8128, 0.3340, 0.8480, 0.8128, 0.3340, 0.8480, 0.8128, 0.3340]]) torch.Size([2, 9])\n"
     ]
    }
   ],
   "source": [
    "#########################张量拼接tensor.cat()\n",
    "#t.cat(seq,dim=0,out=none)\n",
    "#seq是python序列或相同类型的张量序列\n",
    "#dim表示沿此维度拼接\n",
    "#out制定输出\n",
    "a=t.rand(2,3)\n",
    "print(a,a.size())\n",
    "print(\" \")\n",
    "b=t.cat((a,a,a),0)\n",
    "print(b,b.size())\n",
    "print(\" \")\n",
    "c=t.cat((a,a,a),1)\n",
    "print(c,c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      " \n",
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6]],\n",
      "\n",
      "        [[11, 22, 33],\n",
      "         [44, 55, 66]]]) torch.Size([2, 2, 3])\n",
      " \n",
      "tensor([[[ 1,  2,  3],\n",
      "         [11, 22, 33]],\n",
      "\n",
      "        [[ 4,  5,  6],\n",
      "         [44, 55, 66]]]) torch.Size([2, 2, 3])\n",
      " \n",
      "tensor([[[ 1, 11],\n",
      "         [ 2, 22],\n",
      "         [ 3, 33]],\n",
      "\n",
      "        [[ 4, 44],\n",
      "         [ 5, 55],\n",
      "         [ 6, 66]]]) torch.Size([2, 3, 2])\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#########################张量堆叠t.stack([tensor,tensor],dim)\n",
    "a=t.tensor([[1,2,3],[4,5,6]])\n",
    "b=t.tensor([[11,22,33],[44,55,66]])\n",
    "c=t.stack([a,b],0)\n",
    "d=t.stack([a,b],1)\n",
    "e=t.stack([a,b],2)\n",
    "print(a.size())\n",
    "print(\" \")\n",
    "print(c,c.size())\n",
    "print(\" \")\n",
    "print(d,d.size())\n",
    "print(\" \")\n",
    "print(e,e.size())\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1. 1.]\n",
      " \n",
      "[1. 1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "###############tensor与numpy数组之间的转换  tensor.numpy(), t.from_numpy()\n",
    "import numpy as np\n",
    "a=t.ones(6)\n",
    "b=a.numpy()\n",
    "print(a)\n",
    "print(b)\n",
    "print(\" \")\n",
    "a=np.ones(6)\n",
    "b=t.from_numpy(a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
